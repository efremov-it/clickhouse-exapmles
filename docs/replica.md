# Репликация
Репликация в ClickHouse и других базах данных используется для повышения отказоустойчивости и доступности данных.

***От чего защищает репликация:***

1. **Отказ одного или нескольких узлов:**
    - При падении одного или нескольких узлов с репликами (например, из-за аппаратного сбоя) другие узлы с репликами смогут продолжать обслуживать запросы. Это обеспечивает высокую доступность (High Availability, HA) системы.

2. **Отказ дисков и повреждение оборудования:**
    - Если данные на диске повреждаются или диск выходит из строя, другая реплика может продолжать функционировать и принимать запросы на чтение/запись, сохраняя консистентность данных.

3. **Обновления и обслуживание:**
    - Репликация позволяет проводить обновления и обслуживание узлов по очереди, не приводя к недоступности системы в целом.

4. **Балансировка нагрузки:**
    - Репликация помогает распределять нагрузку на чтение, так как запросы могут выполняться на разных репликах, что снижает нагрузку на каждый отдельный узел.

5. **Failover (переключение на другую реплику):**
    - В случае проблем с основным узлом, система может автоматически переключиться на реплику, минимизируя простои и обеспечивая бесперебойную работу.


### Зачем она нужна?

- Обеспечение высокой доступности
- Масштабирование нагрузки
  Есть несколько способов обеспечить масштабирование
  1. Через шардирование
    Недостаток, отказоустойчивость
  2. Через репликацию
    Не проверял
  3. Через шардирование+репликация (для каждого шарда, создается своя репликация)
    Недостаток: нужно иметь в 2 раза больше машин. (2 на шарды 2 на реплики шардов)
    Этот недостаток нивелируется при поднятии контейнеров в kubernetes cluster.
    Как вариант. У нас есть 2 машины в кластере, выделенные именно под clickhouse.
    На каждой ихз них у нас поднято по 2 контейнера
    1. Контейнер с шардом `1`(clickhouse01) контейнер с репликой шарда `2` (clickhouse04)
    2. Контейнер с шардом `2` (clickhouse03) контейнер с репликой шарда `1` (clickhouse02)
    В этом случае, при потере одной из машин, у нас остается в работе как минимум 1 рабочий шард и реплика потерянного шарда.
    Но при стабильной работе кластера, нагрузка на чтение и запись, распределяется равномерно между двумя шардами в кластере.
- Упрощение процесса миграции и обновления

### Взаимодействие компонентов
Для хранения и координации действий репликации в ClickHouse требуется распределённое хранилище данных, которое может гарантировать согласованность состояния. Для этого ClickHouse использует один из двух вариантов: Zookeeper или ClickHouse Keeper.

## Создание сущностей

В рамках MergeTree вы вставляете парты, а ClickHouse будет производить их вставку и слияние с другими партами в фоновом режиме, количество потоков для выполнения фоновых задач можно задать с помощью настройки background_schedule_pool_size.

DDL и TRUNCATE операции также координируются, если применены с ON CLUSTER. Таким образом, почти все операции вставки или изменения таблиц будут реплицироваться, кроме следующих:

CREATE table;
DROP table;
DETACH table;
ATTACH table;
ALTER TABLE FREEZE;
ALTER TABLE MOVE TO DISK;
ALTER TABLE FETCH;

Указанные выше операции являются локальными для инстанса и их необходимо выполнять на всех узлах кластера отдельно.

## Переход
Если в процессе эксплуатации появляется необходимость перейти с нереплицируемой MergeTree таблицы на её Replicated-версию, то есть два основных варианта:

1) Ручной: создать реплицируемую таблицу с таким же движком и структурой, после чего присоединить партиции через ATTACH одну за одной. Этот вариант работает на всех версиях ClickHouse.  

2) Автоматический: можно добавить флаг репликации в каталог таблицы и ClickHouse автоматически преобразует таблицу в реплицируемую. Эта функция была введена в версии 24.2.

На основе все вышеописанного можно заключить, что репликация в ClickHouse — это надёжная конструкция, не обладающая точками отказа. И в целом так оно и есть: по нашему опыту репликация в ClickHouse действительно надёжна и почти никогда не ломается. Почти…


# Важно обратить внимание на:

Keeper должен находится на отдельных серверах, желательно на SSD дисках 3,5 или 7 узлов;

Не стоит очищать Keeper вручную;

Делать бэкап информации из Keeper;

Систематически обновлять версию ClickHouse для возможности использовать все актуальные инструменты;


### Проблемы
1. При удалении контейнера, данные автоматически не реплицируются (имею ввиду что не создается база данных и таблицы)

Данные автоматически реплицируются если разница между данными не велика 

Когда реплика была полностью потеряна (в данном примере это clickhouse01). Или данные с неё были полностью удалены, *нужно создать базу и таблицы руками*.
После создания базы, воссоздание потерянных таблиц может быть проблематично, это связанно с ошибкой 
`Code: 253. DB::Exception: Replica /clickhouse/tables/company_cluster/01/events/replicas/clickhouse01 already exists `
в которой говорится что (потерянная)реплика уже существует, хотя по факту её нет, так происходит из-за того, что на второй реплике (рабочей), сохранилось упоминание о ней.
Для устранения этой ошибки, нужно зайти на (рабочую) реплику и выполнить:
1. Проверить точно ли текущая реплика является клоном потерянной
`SELECT * FROM system.replicas WHERE table = 'events' FORMAT Vertical;`

Премерный вывод
```sh
database:                    company_db
table:                       events
engine:                      ReplicatedMergeTree
is_leader:                   1
can_become_leader:           1
is_readonly:                 0
is_session_expired:          0
future_parts:                0
parts_to_check:              0
zookeeper_path:              /clickhouse/tables/company_cluster/01/events
replica_name:                clickhouse01
replica_path:                /clickhouse/tables/company_cluster/01/events/replicas/clickhouse01
columns_version:             -1
queue_size:                  0
inserts_in_queue:            0
merges_in_queue:             0
part_mutations_in_queue:     0
queue_oldest_time:           1970-01-01 03:00:00
inserts_oldest_time:         1970-01-01 03:00:00
merges_oldest_time:          1970-01-01 03:00:00
part_mutations_oldest_time:  1970-01-01 03:00:00
oldest_part_to_get:          
oldest_part_to_merge_to:     
oldest_part_to_mutate_to:    
log_max_index:               1
log_pointer:                 2
last_queue_update:           1970-01-01 03:00:00
absolute_delay:              0
total_replicas:              2
active_replicas:             2
last_queue_update_exception: 
zookeeper_exception:         
replica_is_active:           {'clickhouse01':1,'clickhouse02':1}
```

2. Удаление метаданных реплики
`SYSTEM DROP REPLICA 'clickhouse01';`

После выполнения этой команды, снова проверяем состояние реплики пердыдущей командой
```sh
zookeeper_exception:         
replica_is_active:           {'clickhouse02':1}
```
3. Создать утерянную таблицу, аналогичным образом как была создана таблица на реплике.
Если нет рядом информации как была создана таблица, можем посмотреть на реплике, используя команду
`SHOW CREATE TABLE events;`

На основе полученного результата, создаем таблицу.
Проводим эту операцию с каждой таблицей.

*После пересоздания таблицы, данные автоматически реплицируются в неё*

4. Провести данную операцию для каждой таблицы.

# **Поведение при нехватке места на одном из шардов**
Если на одном из шардов заканчивается место, ClickHouse будет продолжать записывать данные на другие доступные шарды. Однако на шарде, на котором нет свободного места, любые операции записи будут завершаться ошибками. Поведение системы зависит от стратегии шардирования:

- **Если используется взвешенное шардирование (`weight`):** Данные будут записываться на те шарды, у которых еще есть место. Задача распределения данных между шардовыми узлами будет выполнять балансировку, исходя из веса.
- **Если нет взвешивания:** Запись на полностью заполненный шард будет завершаться ошибкой, но система продолжит функционировать на других шардах.

Для мониторинга свободного места на шардах можно использовать такие SQL-запросы:

```sql
SELECT
    shard,
    free_space,
    total_space,
    free_space / total_space * 100 AS free_space_percent
FROM system.disks
```

### 4. **Рекомендации по управлению шардами**
- Следите за распределением данных, чтобы избежать дисбаланса между шардами.
- Внедрите мониторинг свободного места и состояния шардов для предотвращения ситуаций с нехваткой ресурсов.
- Если возможен сценарий с нехваткой места, стоит использовать стратегию репликации, чтобы данные автоматически распределялись между репликами, что снижает вероятность отказа при записи.

# Настройки для репликации

Для обеспечения отказоустойчивости в кластере ClickHouse с двумя шардов и двумя репликами на каждый шард, необходимо настроить ряд параметров. Вот основные настройки и шаги, которые нужно рассмотреть:

## 1. insert_distributed_sync

Установка значения `<insert_distributed_sync>0</insert_distributed_sync>` в конфигурации ClickHouse приводит к **асинхронной вставке** в распределённые таблицы, что означает, что запрос на вставку возвращает управление клиенту **немедленно**, не дожидаясь завершения вставки на всех репликах. Давайте рассмотрим, как это работает и какие у этого преимущества и недостатки.

### Как это работает:
- **Асинхронная вставка**: При вставке в распределённую таблицу ClickHouse сразу же возвращает успешный ответ клиенту, даже если данные еще не полностью распределены по всем шардам и репликам.
- **Очередь вставки**: Данные сначала записываются на локальную ноду, и затем ClickHouse самостоятельно распределяет их по другим шардам и репликам в фоновом режиме.
- **Нет гарантии синхронной записи на все реплики**: Поскольку вставка асинхронна, данные могут некоторое время не быть доступны на некоторых репликах.

### Преимущества:

1. **Быстрая обратная связь клиенту**:
   - Основное преимущество асинхронной вставки в том, что клиент сразу получает ответ, не дожидаясь окончания записи на все реплики. Это снижает общую задержку и ускоряет обработку массовых операций записи, что полезно в сценариях с большими объемами данных.
   
2. **Улучшенная производительность вставок**:
   - Асинхронная вставка может снизить нагрузку на систему за счет того, что она не требует ждать окончания вставки на все реплики, что улучшает общую производительность системы.

3. **Устойчивость к временным сбоям сети**:
   - Если одна или несколько реплик временно недоступны, это не блокирует вставку. Данные будут отправлены на недоступные реплики, как только они станут доступными, за счет очереди репликации.

### Недостатки:

1. **Неполные данные на репликах**:
   - Если данные еще не распределены на все реплики, запросы на чтение с этих реплик могут не увидеть недавно вставленные данные. Это может привести к неактуальным результатам при распределенных запросах до завершения фоново распределения данных.

2. **Потеря данных при сбое**:
   - Если нода, на которую данные сначала вставляются локально, выйдет из строя до того, как данные успеют быть переданы на другие реплики, есть риск потери данных. Хотя ClickHouse использует механизм репликации и кворум для вставок, в асинхронном режиме такой механизм может не сработать вовремя.

3. **Осложнение диагностики и отладки**:
   - Асинхронная вставка может усложнить отладку, так как при возникновении проблем с распределением данных на реплики ошибки могут проявляться позже, что требует отслеживания логов и статусов репликации.

4. **Задержки при чтении с некоторых реплик**:
   - Если реплики отстают по синхронизации, запросы на чтение с таких реплик могут возвращать неполные или устаревшие данные.

### Сценарии, где это полезно:

1. **Массовые вставки данных**:
   - Асинхронная вставка хорошо подходит для ситуаций, где важно быстро записывать большие объемы данных, например, при сборе логов, метрик или другой телеметрии.

2. **Нагрузочные тесты**:
   - Асинхронная вставка может быть полезной для нагрузочных тестов, где важна высокая пропускная способность при вставках данных.

### Сценарии, где это может вызвать проблемы:

1. **Чувствительные к задержкам чтения системы**:
   - В системах, где важно мгновенно видеть все вставленные данные на всех репликах (например, финансовые приложения, мониторинг в реальном времени), асинхронная вставка может привести к проблемам с целостностью данных.

2. **Критичные вставки с высокой доступностью**:
   - В ситуациях, где важно гарантировать, что данные реплицируются синхронно на все узлы перед тем, как продолжить выполнение запроса, асинхронный подход может быть рискованным.

### Заключение:
- **Преимущества**: Асинхронная вставка ускоряет операции вставки и снижает нагрузку на кластер, что особенно полезно для систем с большим объемом данных.
- **Недостатки**: Возможные проблемы с консистентностью данных на репликах, а также риск потери данных при сбоях.

Если тебе нужно оптимизировать вставки, но при этом не критична моментальная консистентность данных на всех репликах, установка `<insert_distributed_sync>0` будет полезной.

## 2. **Включение внутренней репликации (`internal_replication`)**
   В конфигурации `<remote_servers>` для кластера важно включить внутреннюю репликацию:

```xml
<remote_servers>
    <cluster_name>
        <shard>
            <internal_replication>true</internal_replication>
            <replica>
                <host>clickhouse01</host>
                <port>9000</port>
            </replica>
            <replica>
                <host>clickhouse02</host>
                <port>9000</port>
            </replica>
        </shard>
    </cluster_name>
</remote_servers>
```
Особое внимание нужно обратить на корректное создание таблиц. В кипере таблицы должны иметь название шародов

/clickhouse/tables/{cluster}/{shard}/events

в кипере по итогу, должно быть
```console
/ :) ls "/clickhouse/tables/cluster_2S_2R"
shard01 shard02
/ :) ls "/clickhouse/tables/cluster_2S_2R/shard02/"
events
```

```xml
<clickhouse>
    <macros>
        <shard from_env="CH_SHARD"></shard>
        <replica from_env="HOSTNAME"></replica>
        <cluster>cluster_2S_2R</cluster>
    </macros>
</clickhouse>
```

при этом, при падении обоих реплик одного шарда, кластер сможет продолжать работу, сохраняя данные на локальном диске

```console
/var/lib/clickhouse/store
3df/3df13b2e-eca5-42c2-a154-f3ff401a2592:
shard2_all_replicas
```
как только одна из реплик шарда станет доступна, данные будут записаны на неё.
как только другие реплики будут доступны, они скопируют данные с доступной реплики.

## 3. **Настройка отказоустойчивости и кворума**
   Для поддержания работы кластера при падении одной или двух реплик на уровне шарда, нужно настроить кворумные вставки и чтение:

   - **Запись с кворумом**:
     Включите кворумную запись, чтобы записанные данные гарантированно сохранялись как минимум на одной реплике каждого шарда:
     
     ```xml
     <insert_quorum>1</insert_quorum>
     <insert_quorum_timeout>60</insert_quorum_timeout>
     ```
     Это обеспечит, что данные будут вставлены хотя бы на одной реплике даже в случае отказа других.

   - **Чтение с одного реплика**:
     Можно настроить запросы чтения на использование одной доступной реплики (например, если одна реплика недоступна):
     
     ```xml
     <prefer_localhost_replica>true</prefer_localhost_replica>
     ```

## 4. **Режим работы при сбоях (emergency mode)**
   Если падет несколько реплик, то необходимо, чтобы оставшиеся реплики продолжали обработку запросов на чтение и запись:

   - **Настройка распределенных таблиц**:
     Используйте настройки для работы с распределенными таблицами, которые будут позволять кластеру продолжать вставку данных и чтение с оставшихся реплик:

     ```sql
     CREATE TABLE distributed_table AS local_table
     ENGINE = Distributed(cluster_name, database_name, table_name, 'replica_1', 1);
     ```

     Это гарантирует, что даже в случае сбоя нескольких реплик, оставшиеся реплики продолжат получать данные и их обслуживать.

## 5. **Автоматическая синхронизация после восстановления**
   Важно настроить автоматическую синхронизацию реплик после их восстановления. Это делается за счет использования механизма **MergeTree**, который автоматически синхронизирует недостающие данные при восстановлении реплики:

   - **MergeTree** автоматически синхронизирует данные при подключении восстановленной реплики к кластеру.
   - Обратите внимание на настройки таких параметров, как:
     ```xml
     <max_replicated_merges_in_queue>32</max_replicated_merges_in_queue>
     ```
     чтобы убедиться, что процесс слияния и синхронизации данных будет работать эффективно при восстановлении.

## 6. **Проверка состояния реплик и очереди репликации**
   Следует регулярно проверять таблицу `system.replication_queue`, чтобы убедиться, что очереди репликации накапливаются в случае падения реплик, а также что синхронизация данных происходит корректно после их восстановления.

### Заключение:
Эти настройки обеспечат:
- **Отказоустойчивость**: Кластер продолжит работать, даже если одна или две реплики (одна в каждом шарде) выйдут из строя.
- **Асинхронную репликацию**: Данные будут временно храниться локально при отсутствии одной из реплик, а затем синхронизированы.
- **Автоматическое восстановление**: После восстановления реплик, данные будут автоматически синхронизированы на них.

Этот подход позволит достичь высокой доступности и продолжить работу в аварийных ситуациях без сбоев в работе запросов.
